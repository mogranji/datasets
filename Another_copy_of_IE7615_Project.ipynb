{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mogranji/datasets/blob/master/Another_copy_of_IE7615_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import all the required Libraries"
      ],
      "metadata": {
        "id": "-WM_69C1rrUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Augmentor"
      ],
      "metadata": {
        "id": "ClaLCNu1GcUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-plot"
      ],
      "metadata": {
        "id": "EBs7eCNMGn4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFWUtiO4C19I"
      },
      "outputs": [],
      "source": [
        "# Import Tensorflow and Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "#Image processing libraries\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import load_model\n",
        "import pickle\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import Augmentor\n",
        "\n",
        "#import libraries for data processing and classification evaluate\\\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scikitplot as skplt\n",
        "\n",
        "#import system library\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9YIRCKGS7P8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label images"
      ],
      "metadata": {
        "id": "gH0E-LvZQ04j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the directory where your images are located\n",
        "image_dir = '/content/drive/MyDrive/IE7615/Cropped Classified'  # Change this to your image directory path\n",
        "\n",
        "def ImageLabel(image_dir):\n",
        "\n",
        "  # Initialize empty lists to store image paths and labels\n",
        "  image_paths = []\n",
        "  labels = []\n",
        "\n",
        "  # Loop through the subdirectories (class labels)\n",
        "  for label in os.listdir(image_dir):\n",
        "      label_path = os.path.join(image_dir, label)\n",
        "      if os.path.isdir(label_path):\n",
        "          for image in os.listdir(label_path):\n",
        "              # Ensure the file is an image (you can add more extensions as needed)\n",
        "              if image.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
        "                  image_path = os.path.join(label_path, image)\n",
        "                  image_paths.append(image_path)\n",
        "                  labels.append(label)\n",
        "  return(image_paths, labels)"
      ],
      "metadata": {
        "id": "rLGUsp4NQ8GA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagePath,labels =ImageLabel(image_dir)\n",
        "# Create a DataFrame from the lists\n",
        "df = pd.DataFrame({'imagePath': imagePath, 'label': labels})\n",
        "#Show the df\n",
        "df"
      ],
      "metadata": {
        "id": "uCeHkDD6iAEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].unique()"
      ],
      "metadata": {
        "id": "R7YiHVxSlBJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def subStrRemoval():\n",
        "  subStr = ['01 ', '02 ','03 ', '04 ','05 ']\n",
        "  for i in subStr:\n",
        "    df['label'] = df['label'].str.replace(i, '')\n",
        "  return df"
      ],
      "metadata": {
        "id": "pF7AeIih8oIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = subStrRemoval()\n",
        "df1"
      ],
      "metadata": {
        "id": "skaW1BUI9Bk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "qIrVJL1FryTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(df1['label'])\n",
        "encoded_y = encoder.transform(df1['label'])\n",
        "counts = np.bincount(encoded_y)\n",
        "print(counts)\n",
        "fig, ax = plt.subplots()\n",
        "plt.bar(list(range(5)), counts)\n",
        "ax.set_xticklabels(('', 'Basophil', 'Eosinophil', 'Lymphocyte', 'Monocyte', 'Neutrophil'))\n",
        "ax.set_ylabel('Counts')"
      ],
      "metadata": {
        "id": "nic_DeWXcJ2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split and Augment Images"
      ],
      "metadata": {
        "id": "F-NcjbeZ_O0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Balancing"
      ],
      "metadata": {
        "id": "vcpK5FXS_Rv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "metadata": {
        "id": "ydymNWRIhr8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def balance_set(df, x_cols, y_cols):\n",
        "    ros = RandomOverSampler(random_state=42)\n",
        "\n",
        "    x_multi, y_multi = ros.fit_resample(df[x_cols], df[y_cols].values)\n",
        "    data = pd.concat([x_multi, pd.DataFrame(y_multi, columns= y_cols)], axis=1)\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "ziXCN3xGhM4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_multi = balance_set(df,\n",
        "                          x_cols = [\"imagePath\"],\n",
        "                          y_cols = ['label'])\n",
        "\n",
        "train_multi"
      ],
      "metadata": {
        "id": "z1BvTBwLiwP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(train_multi['label'])\n",
        "encoded_y = encoder.transform(train_multi['label'])\n",
        "counts = np.bincount(encoded_y)\n",
        "print(counts)\n",
        "fig, ax = plt.subplots()\n",
        "plt.bar(list(range(5)), counts)\n",
        "ax.set_xticklabels(('', 'Basophil', 'Eosinophil', 'Lymphocyte', 'Monocyte', 'Neutrophil'))\n",
        "ax.set_ylabel('Counts')"
      ],
      "metadata": {
        "id": "XrOe9AJGi1XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Monocyte = train_multi[train_multi['label'] == 'Monocyte'].count()[1]\n",
        "Eosinophil = train_multi[train_multi['label'] == 'Eosinophil'].count()[1]\n",
        "Basophil = train_multi[train_multi['label'] == 'Basophil'].count()[1]\n",
        "Neutrophil = train_multi[train_multi['label'] == 'Neutrophil'].count()[1]\n",
        "Lymphocyte = train_multi[train_multi['label'] == 'Lymphocyte'].count()[1]\n",
        "total = len(train_multi)\n",
        "\n",
        "print('Count of sample in each class is: \\n')\n",
        "print(f'Monocyte: {Monocyte} ({round(Monocyte/total,2)*100}%)')\n",
        "print(f'Eosinophil: {Eosinophil} ({round(Eosinophil/total,2)*100}%)')\n",
        "print(f'Basophil: {Basophil} ({round(Basophil/total,2)*100}%) ')\n",
        "print(f'Neutrophil: {Neutrophil} ({round(Neutrophil/total,2)*100}%)')\n",
        "print(f'Lymphocyte: {Lymphocyte} ({round(Lymphocyte/total,2)*100}%)')"
      ],
      "metadata": {
        "id": "1OIQAHxC868b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "listFolders = os.listdir(image_dir)\n",
        "pathList = []\n",
        "for i in listFolders:\n",
        "  pathList.append(os.path.join(image_dir,i))\n",
        "\n",
        "Monocyte = pathList[0]\n",
        "Eosinophil = pathList[1]\n",
        "Basophil = pathList[2]\n",
        "Neutrophil = pathList[3]\n",
        "Lymphocyte = pathList[4]"
      ],
      "metadata": {
        "id": "TG3KQdbw_2WR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainImage, trainLabel = train_multi['imagePath'], train_multi['label']\n",
        "train = pd.DataFrame({'train_imagePath': trainImage, 'train_label': trainLabel})\n",
        "train"
      ],
      "metadata": {
        "id": "zNKePee_CWrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Train Spling"
      ],
      "metadata": {
        "id": "cao8VvXWsZAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training and Validation Split\n",
        "df_train, df_val = train_test_split(train, test_size=0.25, random_state=42, shuffle=True, stratify=train['train_label'])\n",
        "df_train"
      ],
      "metadata": {
        "id": "GyGBCeOREgvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training and Validation Split\n",
        "df_test, df_val = train_test_split(df_val, test_size=0.4, random_state=42, shuffle=True, stratify=df_val['train_label'])\n",
        "df_val"
      ],
      "metadata": {
        "id": "MExJVQMun97v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "id": "PKVpnEkCljIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Generator Function"
      ],
      "metadata": {
        "id": "XjkOot9PGA92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define image size and parameters\n",
        "batch_size = 64\n",
        "img_height = 128\n",
        "img_width =  128\n",
        "\n",
        "image_size = (img_height, img_width)\n",
        "input_shape = (img_height, img_width, 3)"
      ],
      "metadata": {
        "id": "yAT48SvBF-BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of ImageDataGenerator for Traing set only\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255)#,brightness_range=[1,1],featurewise_std_normalization=True,featurewise_center=True,horizontal_flip=True,\n",
        "    #vertical_flip=True)\n",
        "#,height_shift_range=0.0, rotation_range=60, fill_mode='wrap')"
      ],
      "metadata": {
        "id": "_biRQ7iuK_Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_trn = train_datagen.flow_from_dataframe(df_train,\n",
        "  x_col='train_imagePath',\n",
        "  y_col='train_label',\n",
        "  target_size=input_shape[:2], # Resize images to the specified size\n",
        "  class_mode='categorical', # For multi-class classification\n",
        "  shuffle = False,\n",
        "  batch_size=batch_size,\n",
        "  keep_aspect_ratio=True)"
      ],
      "metadata": {
        "id": "LxLtbMNtXPbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of ImageDataGenerator for Validation and Test sets\n",
        "test_datagen = ImageDataGenerator(\n",
        "        rescale=1./255)\n",
        "#,brightness_range=[1,1],featurewise_std_normalization=True,featurewise_center=True,horizontal_flip=True,\n",
        "    #vertical_flip=True)\n",
        "  #height_shift_range=0.0, rotation_range=60, fill_mode='wrap')"
      ],
      "metadata": {
        "id": "nd-MVxFAL2aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_val = test_datagen.flow_from_dataframe(df_val,\n",
        " x_col='train_imagePath',\n",
        "  y_col='train_label',\n",
        "  target_size=input_shape[:2], # Resize images to the specified size\n",
        "  class_mode='categorical', # For multi-class classification\n",
        "  shuffle = False,\n",
        "  color_mode='rgb',\n",
        "  batch_size=batch_size,\n",
        "  keep_aspect_ratio=True)"
      ],
      "metadata": {
        "id": "LTjqcce7pETv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_test = test_datagen.flow_from_dataframe(df_test,\n",
        " x_col='train_imagePath',\n",
        "  y_col='train_label',\n",
        "  target_size=input_shape[:2], # Resize images to the specified size\n",
        "  class_mode='categorical', # For multi-class classification\n",
        "  shuffle = False,\n",
        "  color_mode='rgb',\n",
        "  batch_size=batch_size,\n",
        "  keep_aspect_ratio=True)"
      ],
      "metadata": {
        "id": "JQ0AfPN1MVnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ds_trn.class_indices.keys()\n",
        "class_names"
      ],
      "metadata": {
        "id": "VKFo8osBRZ5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Show Sample Image"
      ],
      "metadata": {
        "id": "N3cw5Kc7QVU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def showSample(data, batchsize=25):\n",
        "  classes = list(data.class_indices.keys()) # get the classes of the data\n",
        "  image, labels = next(data)\n",
        "\n",
        "  length = len(labels)\n",
        "  sample = min(length,batchsize)\n",
        "\n",
        "  plt.figure(figsize=(round(batchsize*2), round(batchsize*2)))\n",
        "  m = 0\n",
        "  b = batchsize\n",
        "  while b>1:\n",
        "    m+=1\n",
        "    b = b/2\n",
        "\n",
        "  for i in range(sample):\n",
        "    plt.subplot(m, m, i+1)\n",
        "    plt.imshow(image[i])\n",
        "    index = np.argmax(labels[i])\n",
        "    plt.title(classes[index],fontsize = m*6)\n",
        "    plt.axis('off')\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "D7PcsjA7QkH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "showSample(ds_trn)"
      ],
      "metadata": {
        "id": "7XLCckKqU-L9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "showSample(ds_test)"
      ],
      "metadata": {
        "id": "bsF3R4mPxkRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Early Stopping"
      ],
      "metadata": {
        "id": "-dX1p1j5Z4GR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define CallBack\n",
        "class FinalCallBack(tf.keras.callbacks.Callback):\n",
        " def on_epoch_end(self, epoch, logs=None):\n",
        "  print(\"\\n****************\\n\\nThe average loss for epoch {} is{:7.3f} and accuracy is{:7.3f}.\".format(epoch+1, logs[\"loss\"], logs[\"accuracy\"]),\n",
        "  \"\\n\\n***************\\n\")\n",
        "\n",
        "EarlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
        "  mode='max',\n",
        "  min_delta = 0.01,\n",
        "  baseline = 0.5,\n",
        "  patience = 10,\n",
        "  restore_best_weights = True)"
      ],
      "metadata": {
        "id": "LIYYXQ2eSOA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Fit"
      ],
      "metadata": {
        "id": "qf9JVNCdcB50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic CNN Model"
      ],
      "metadata": {
        "id": "KT5SiPXTq_TN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Sequential model with modified architecture\n",
        "model = tf.keras.Sequential([\n",
        "  #for equal regularization\n",
        "  tf.keras.layers.SeparableConv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), activation=\"tanh\", input_shape=input_shape),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), activation=\"relu\"),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  tf.keras.layers.SeparableConv2D(filters=128, kernel_size=(3,3), strides = (1,1), activation=\"relu\",padding='same'),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2),padding='same'),\n",
        "  tf.keras.layers.SpatialDropout2D(rate=0.1),\n",
        "  tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides = (1,1), activation=\"relu\",padding='same'),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2),padding='same'),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128,activation='elu'),\n",
        "  tf.keras.layers.Dropout(rate=0.2),\n",
        "  tf.keras.layers.Dense(64,activation='relu'),\n",
        "  tf.keras.layers.Dense(5, activation='softmax')\n",
        "], name='CNNModel')\n",
        "# Compile the model with the modified optimizer\n",
        "#sgd_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "8z8EDqda1Jlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "ZGOOXF76ZChg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit1 = model.fit(ds_trn,\n",
        "  epochs= 50,\n",
        "  batch_size = 64,\n",
        "  verbose= 1,\n",
        "  callbacks=[FinalCallBack(),EarlyStopping], validation_data = ds_val)"
      ],
      "metadata": {
        "id": "MRCtW0adZLOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_train_result(fit):\n",
        "  a = fit.history['accuracy']\n",
        "  b = fit.history['val_accuracy']\n",
        "  c = fit.history['loss']\n",
        "  d = fit.history['val_loss']\n",
        "\n",
        "  best_acc = np.argmax(b)\n",
        "  high_acc = b[best_acc]\n",
        "\n",
        "  best_loss = np.argmin(d)\n",
        "  low_loss = d[best_loss]\n",
        "\n",
        "  plt.figure(figsize=(10,5))\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(a, label='Tarining Accuracy')\n",
        "  plt.plot(b, label='Validation Accuracy')\n",
        "  plt.scatter(best_acc+1, high_acc, s= 150, c= 'red', label= f'Best Epoch = {best_acc+1}')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.title('Tarining and Validation Accuracy')\n",
        "  plt.legend()\n",
        "  plt.grid()\n",
        "\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(c, label='Traing Loss')\n",
        "  plt.plot(d, label='validation Loss')\n",
        "  plt.scatter(best_loss+1, low_loss, s= 150, c= 'red', label= f'Best Epoch = {best_loss+1}')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.title('Tarining and Validation Loss')\n",
        "  plt.grid()\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "6AHVCiD_yxdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_train_result(fit1)"
      ],
      "metadata": {
        "id": "XddpHJd97Blm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATE TEST SET PERFORMANCE\n",
        "# YOUR CODE HERE (THIS SHOULD BE A SINGLE LINE OF CODE, RESULTING IN PRINTOUT OF TEST-SET PERFORMANCE VALUE)\n",
        "model.evaluate(ds_test)"
      ],
      "metadata": {
        "id": "ZlBs4azZ6qn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = model.predict(ds_test)\n",
        "y_predict = np.argmax(y_predict, axis=1)\n",
        "class_names = ds_trn.class_indices.keys()\n",
        "print(classification_report(ds_test.classes, y_predict, target_names=class_names))"
      ],
      "metadata": {
        "id": "epCjWV9cMjdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skplt.metrics.plot_confusion_matrix(ds_test.classes, y_predict,\n",
        "                                      normalize = False,\n",
        "                                      title = \"Confusion Matrix\",\n",
        "                                    figsize = (10, 10))"
      ],
      "metadata": {
        "id": "zpxgyK8gnvEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skplt.metrics.plot_confusion_matrix(ds_test.classes, y_predict,\n",
        "                                      normalize = True,\n",
        "                                      title = \"Normalized Confusion Matrix\",\n",
        "                                    figsize = (10, 10))"
      ],
      "metadata": {
        "id": "meX2RRIpn7lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base CNN Model with more parameters"
      ],
      "metadata": {
        "id": "6lwwvu-xrmxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CNNA1 = tf.keras.Sequential([\n",
        " tf.keras.layers.SeparableConv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), activation=\"tanh\", input_shape=input_shape),\n",
        " tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        " tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides = (1,1), activation=\"relu\",padding='same'),\n",
        " tf.keras.layers.MaxPooling2D(pool_size=(2, 2),padding='same'),\n",
        " tf.keras.layers.SpatialDropout2D(rate=0.1),\n",
        " tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides = (1,1), activation=\"relu\",padding='same'),\n",
        " tf.keras.layers.MaxPooling2D(pool_size=(2, 2),padding='same'),\n",
        " tf.keras.layers.Flatten(),\n",
        " tf.keras.layers.Dense(128,activation='elu'),\n",
        " tf.keras.layers.Dropout(rate=0.2),\n",
        " tf.keras.layers.Dense(32,activation='relu'),\n",
        " tf.keras.layers.Dense(5, activation='softmax')\n",
        "], name='CNNModel')\n",
        "\n",
        "\n",
        "CNNA1.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "bEu4NQJGiV7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNNA1.summary()"
      ],
      "metadata": {
        "id": "9oIkAQK9qenA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(CNNA1, show_shapes=True)"
      ],
      "metadata": {
        "id": "rxaXfjipr1fN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit2 = CNNA1.fit(ds_trn,\n",
        "  epochs= 50,\n",
        "  batch_size = 64,\n",
        "  verbose= 1,\n",
        "  callbacks=[FinalCallBack(),EarlyStopping],\n",
        "  validation_data= ds_val)"
      ],
      "metadata": {
        "id": "E1cqu8ofqx9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_train_result(fit2)"
      ],
      "metadata": {
        "id": "0rW_bl3grFtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATE TEST SET PERFORMANCE\n",
        "# YOUR CODE HERE (THIS SHOULD BE A SINGLE LINE OF CODE, RESULTING IN PRINTOUT OF TEST-SET PERFORMANCE VALUE)\n",
        "CNNA1.evaluate(ds_test)"
      ],
      "metadata": {
        "id": "lSS4gQ9X_gQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = CNNA1.predict(ds_test)\n",
        "y_predict = np.argmax(y_predict, axis=1)\n",
        "class_names = ds_trn.class_indices.keys()\n",
        "print(classification_report(ds_test.classes, y_predict, target_names=class_names))"
      ],
      "metadata": {
        "id": "aDGVrIo5_pWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skplt.metrics.plot_confusion_matrix(ds_test.classes, y_predict,\n",
        "                                      normalize = False,\n",
        "                                      title = \"Confusion Matrix\",\n",
        "                                    figsize = (10, 10))\n"
      ],
      "metadata": {
        "id": "14WUYUbHyJ3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skplt.metrics.plot_confusion_matrix(ds_test.classes, y_predict,\n",
        "                                      normalize = True,\n",
        "                                      title = \"Nomalized Confusion Matrix\",\n",
        "                                    figsize = (10, 10))"
      ],
      "metadata": {
        "id": "-9EuBh-jyNYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base CNN Model with Batch Normalization"
      ],
      "metadata": {
        "id": "9eG6tJCJrMxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CNNH2N = tf.keras.Sequential([\n",
        " tf.keras.layers.SeparableConv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), activation=\"tanh\", input_shape=input_shape),\n",
        " tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        " BatchNormalization(),\n",
        " tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), activation=\"relu\"),\n",
        " tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        " BatchNormalization(),\n",
        " tf.keras.layers.SeparableConv2D(filters=128, kernel_size=(3,3), strides = (1,1), activation=\"relu\",padding='same'),\n",
        " tf.keras.layers.MaxPooling2D(pool_size=(2, 2),padding='same'),\n",
        " BatchNormalization(),\n",
        " tf.keras.layers.SpatialDropout2D(rate=0.1),\n",
        " tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides = (1,1), activation=\"relu\",padding='same'),\n",
        " tf.keras.layers.MaxPooling2D(pool_size=(2, 2),padding='same'),\n",
        " BatchNormalization(),\n",
        " tf.keras.layers.Flatten(),\n",
        " tf.keras.layers.Dense(128,activation='elu'),\n",
        " BatchNormalization(),\n",
        " tf.keras.layers.Dropout(rate=0.2),\n",
        " tf.keras.layers.Dense(32,activation='relu'),\n",
        " BatchNormalization(),\n",
        " tf.keras.layers.Dense(5, activation='softmax')\n",
        "], name='CNNModel')\n",
        "\n",
        "\n",
        "CNNH2N.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "CNNH2N.summary()\n",
        "\n",
        "CNNH2N.summary()"
      ],
      "metadata": {
        "id": "7ZLBW-vH_9lQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(CNNH2N, show_shapes=True)"
      ],
      "metadata": {
        "id": "8T__HdR9yZaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit3 = CNNH2N.fit(ds_trn,\n",
        "  epochs= 50,\n",
        "  batch_size = 64,\n",
        "  verbose= 1,\n",
        "  callbacks=[FinalCallBack(),EarlyStopping],\n",
        "  validation_data= ds_val)"
      ],
      "metadata": {
        "id": "_NpCneJ3GNsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATE TEST SET PERFORMANCE\n",
        "# YOUR CODE HERE (THIS SHOULD BE A SINGLE LINE OF CODE, RESULTING IN PRINTOUT OF TEST-SET PERFORMANCE VALUE)\n",
        "CNNH2N.evaluate(ds_test)"
      ],
      "metadata": {
        "id": "wXRbQlBGHjGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = CNNH2N.predict(ds_test)\n",
        "y_predict = np.argmax(y_predict, axis=1)\n",
        "class_names = ds_trn.class_indices.keys()\n",
        "print(classification_report(ds_test.classes, y_predict, target_names=class_names))"
      ],
      "metadata": {
        "id": "DR5v0DTjH1b1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skplt.metrics.plot_confusion_matrix(ds_test.classes, y_predict,\n",
        "                                      normalize = False,\n",
        "                                      title = \"Confusion Matrix\",\n",
        "                                    figsize = (10, 10))"
      ],
      "metadata": {
        "id": "SLKYjs7G2wja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skplt.metrics.plot_confusion_matrix(ds_test.classes, y_predict,\n",
        "                                      normalize = True,\n",
        "                                      title = \"Nomalized Confusion Matrix\",\n",
        "                                    figsize = (10, 10))"
      ],
      "metadata": {
        "id": "0cAFk3ja2zC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG-Model"
      ],
      "metadata": {
        "id": "PXGqKdVPyunZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import models,optimizers, regularizers\n",
        "# Define the batch size\n",
        "batch_size = 64\n",
        "# Define the number of classes in your dataset\n",
        "num_classes = 5\n",
        "# Create the VGGNet model with BatchNormalization and Dropout\n",
        "def create_vgg_model(input_shape, num_classes):\n",
        " vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        " # Freeze the VGG16 layers\n",
        " for layer in vgg_model.layers:\n",
        "  layer.trainable = False\n",
        " model = models.Sequential()\n",
        " model.add(vgg_model)\n",
        " model.add(layers.Flatten())\n",
        " model.add(layers.Dense(4096, activation='relu'))\n",
        " model.add(layers.BatchNormalization())\n",
        " model.add(layers.Dropout(0.5))\n",
        "\n",
        " model.add(layers.Dense(4096, activation='relu'))\n",
        " model.add(layers.BatchNormalization())\n",
        " model.add(layers.Dropout(0.5))\n",
        "\n",
        " model.add(layers.Dense(num_classes, activation='softmax'))\n",
        " return model\n",
        "# Create the VGGNet model\n",
        "modelvgg = create_vgg_model(input_shape, num_classes)"
      ],
      "metadata": {
        "id": "iRUPXca_JJFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "#optimizer = optimizers.Adam(learning_rate=0.001)\n",
        "modelvgg.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# Print the model summary\n",
        "modelvgg.summary()"
      ],
      "metadata": {
        "id": "9iLDcdGxJj5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(modelvgg, show_shapes=True)"
      ],
      "metadata": {
        "id": "51XV4Y7r29d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit4 = modelvgg.fit(ds_trn,\n",
        "  epochs= 50,\n",
        "  batch_size = 64,\n",
        "  verbose= 1,\n",
        "  callbacks=[FinalCallBack(),EarlyStopping],\n",
        "  validation_data= ds_val)"
      ],
      "metadata": {
        "id": "Z83Z_6-SJ9We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_train_result(fit4)"
      ],
      "metadata": {
        "id": "zVH1BS53KU7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATE TEST SET PERFORMANCE\n",
        "# YOUR CODE HERE (THIS SHOULD BE A SINGLE LINE OF CODE, RESULTING IN PRINTOUT OF TEST-SET PERFORMANCE VALUE)\n",
        "modelvgg.evaluate(ds_test)"
      ],
      "metadata": {
        "id": "XD-G8naRS-FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = modelvgg.predict(ds_test)\n",
        "y_predict = np.argmax(y_predict, axis=1)\n",
        "class_names = ds_trn.class_indices.keys()\n",
        "print(classification_report(ds_test.classes, y_predict, target_names=class_names))"
      ],
      "metadata": {
        "id": "31lVLkUQTFyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skplt.metrics.plot_confusion_matrix(ds_test.classes, y_predict,\n",
        "                                      normalize = False,\n",
        "                                      title = \"Confusion Matrix\",\n",
        "                                    figsize = (10, 10))"
      ],
      "metadata": {
        "id": "rKMpQo3YTWDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skplt.metrics.plot_confusion_matrix(ds_test.classes, y_predict,\n",
        "                                      normalize = True,\n",
        "                                      title = \"Normalized Confusion Matrix\",\n",
        "                                    figsize = (10, 10))"
      ],
      "metadata": {
        "id": "jrlhSvTjVisV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resnet Model"
      ],
      "metadata": {
        "id": "4lXjtCkMRoTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def identity_block(input, filters):\n",
        " filter1, filter2, filter3 = filters\n",
        " x = tf.keras.layers.Conv2D(filter1, (1,1))(input)\n",
        " x = tf.keras.layers.BatchNormalization()(x)\n",
        " x = tf.keras.activations.relu(x)\n",
        " x = tf.keras.layers.Conv2D(filter2, (3,3), padding='same')(x)\n",
        " x = tf.keras.layers.BatchNormalization()(x)\n",
        " x = tf.keras.activations.relu(x)\n",
        " x = tf.keras.layers.Conv2D(filter3, (1,1))(x)\n",
        " x = tf.keras.layers.BatchNormalization()(x)\n",
        " x = tf.keras.layers.add([x, input])\n",
        " x = tf.keras.activations.relu(x)\n",
        " return x"
      ],
      "metadata": {
        "id": "FyDs7fWFGz0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(input, filters, strides):\n",
        " filter1, filter2, filter3 = filters\n",
        " x = tf.keras.layers.Conv2D(filter1, (1,1), strides=strides)(input)\n",
        " x = tf.keras.layers.BatchNormalization()(x)\n",
        " x = tf.keras.activations.relu(x)\n",
        " x = tf.keras.layers.Conv2D(filter2, (3,3), padding='same')(x)\n",
        " x = tf.keras.layers.BatchNormalization()(x)\n",
        " x = tf.keras.activations.relu(x)\n",
        " x = tf.keras.layers.Conv2D(filter3, (1,1))(x)\n",
        " x = tf.keras.layers.BatchNormalization()(x)\n",
        " tmp = tf.keras.layers.Conv2D(filter3, (1,1), strides=strides)(input)\n",
        " tmp = tf.keras.layers.BatchNormalization()(tmp)\n",
        " x = layers.add([x, tmp])\n",
        " x = tf.keras.activations.relu(x)\n",
        " return x"
      ],
      "metadata": {
        "id": "ArEGgHOwRt41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_res50 = tf.keras.Sequential()"
      ],
      "metadata": {
        "id": "qyLtqc7eRxlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet50():\n",
        " input = tf.keras.Input(shape = input_shape)\n",
        " x = tf.keras.layers.ZeroPadding2D((3,3))(input)\n",
        " x = tf.keras.layers.Conv2D(64, (7,7), strides=(2,2))(input)\n",
        " x = tf.keras.layers.BatchNormalization()(x)\n",
        " x = tf.keras.activations.relu(x)\n",
        " x = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides=(2,2))(x)\n",
        " x = conv_block(x, [64,64,256], strides=(1,1))\n",
        " x = identity_block(x, [64,64,256])\n",
        " x = identity_block(x, [64,64,256])\n",
        " x = conv_block(x, [128,128,512], strides=(2,2))\n",
        " x = identity_block(x, [128,128,512])\n",
        " x = identity_block(x, [128,128,512])\n",
        " x = identity_block(x, [128,128,512])\n",
        " x = conv_block(x, [256,256,1024], strides=(2,2))\n",
        " x = identity_block(x, [256,256,1024])\n",
        " x = identity_block(x, [256,256,1024])\n",
        " x = identity_block(x, [256,256,1024])\n",
        " x = identity_block(x, [256,256,1024])\n",
        " x = identity_block(x, [256,256,1024])\n",
        " x = conv_block(x, [512,512,2048], strides=(2,2))\n",
        " x = identity_block(x, [512,512,2048])\n",
        " x = identity_block(x, [512,512,2048])\n",
        " x = tf.keras.layers.AveragePooling2D(pool_size=(3,3),padding='same')(x)\n",
        " x = tf.keras.layers.Flatten()(x)\n",
        " output = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
        " model = tf.keras.models.Model(input, output)\n",
        " return model\n"
      ],
      "metadata": {
        "id": "tVXDRWzkRzu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resNet50 = resnet50()\n",
        "resNet50.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "resNet50.summary()"
      ],
      "metadata": {
        "id": "BvLBrNa3R21x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(resNet50, show_shapes=True)"
      ],
      "metadata": {
        "id": "YHhj5lLZR5o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = resNet50.fit(ds_trn,\n",
        "  epochs= 50,\n",
        "  batch_size = 64,\n",
        "  verbose= 1,\n",
        "  callbacks=[FinalCallBack(),EarlyStopping],\n",
        "  validation_data= ds_val)"
      ],
      "metadata": {
        "id": "5p0DFUDsStnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATE TEST SET PERFORMANCE\n",
        "# YOUR CODE HERE (THIS SHOULD BE A SINGLE LINE OF CODE, RESULTING IN PRINTOUT OF TEST-SET PERFORMANCE VALUE)\n",
        "resNet50.evaluate(ds_test)"
      ],
      "metadata": {
        "id": "YdNQlOr1nycf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = modelvgg.predict(ds_test)\n",
        "y_predict = np.argmax(y_predict, axis=1)\n",
        "class_names = ds_trn.class_indices.keys()\n",
        "print(classification_report(ds_test.classes, y_predict, target_names=class_names))"
      ],
      "metadata": {
        "id": "wMvKT-Z0cIGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skplt.metrics.plot_confusion_matrix(ds_test.classes, y_predict,\n",
        "                                      normalize = False,\n",
        "                                      title = \"Confusion Matrix\",\n",
        "                                    figsize = (10, 10))"
      ],
      "metadata": {
        "id": "7lWlXKBCcUaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skplt.metrics.plot_confusion_matrix(ds_test.classes, y_predict,\n",
        "                                      normalize = True,\n",
        "                                      title = \"Nomalized Confusion Matrix\",\n",
        "                                    figsize = (10, 10))"
      ],
      "metadata": {
        "id": "yECZSoHQcf5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qLEhgF4_cj0s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}